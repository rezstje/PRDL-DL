{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-19 11:43:31.191401: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-01-19 11:43:31.191472: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-01-19 11:43:31.221632: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-01-19 11:43:31.284634: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-01-19 11:43:32.240173: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from data_processing import Data_retrieval_and_processing \n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "\n",
    "path_data = \"Data/\"\n",
    "\n",
    "train_data_intra = Data_retrieval_and_processing(path_data + \"Intra/train/\", save = False)\n",
    "test_data_intra = Data_retrieval_and_processing(path_data + \"Intra/test/\", save = False)\n",
    "actual_shape = np.array(test_data_intra.processed_matrices).shape\n",
    "\n",
    "train_data_cross = Data_retrieval_and_processing(path_data + \"Cross/train/\", save = False)\n",
    "test_data_cross1 = Data_retrieval_and_processing(path_data + \"Cross/test1/\", save = False)\n",
    "test_data_cross2 = Data_retrieval_and_processing(path_data + \"Cross/test2/\", save = False)\n",
    "test_data_cross3 = Data_retrieval_and_processing(path_data + \"Cross/test3/\", save = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-19 11:44:02.939787: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-19 11:44:03.119816: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-19 11:44:03.120202: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-19 11:44:03.128336: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-19 11:44:03.128560: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-19 11:44:03.128746: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-19 11:44:03.252862: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-19 11:44:03.253318: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-19 11:44:03.253600: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:901] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-01-19 11:44:03.253750: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1929] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 2232 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3050 Ti Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n",
      "2024-01-19 11:44:15.092007: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 141356032 exceeds 10% of free system memory.\n",
      "2024-01-19 11:44:15.332628: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 141356032 exceeds 10% of free system memory.\n",
      "2024-01-19 11:44:17.893351: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 141356032 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 3s 3s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-19 11:44:18.283746: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:454] Loaded cuDNN version 8904\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 1s/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-19 11:44:33.402509: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 282712064 exceeds 10% of free system memory.\n",
      "2024-01-19 11:44:33.878133: W external/local_tsl/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 282712064 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 1s 104ms/step\n",
      "1/1 [==============================] - 1s 995ms/step\n",
      "1/1 [==============================] - 0s 107ms/step\n",
      "1/1 [==============================] - 0s 105ms/step\n",
      "lstm intra train accuracy = 3.9375\n",
      "lstm intra test accuracy = 3.75\n",
      "lstm cross train accuracy = 4.0\n",
      "lstm cross test 1 accuracy = 3.125\n",
      "lstm cross test 2 accuracy = 2.875\n",
      "lstm cross test 3 accuracy = 3.125\n",
      "lstm cross test all accuracy = 3.0416666666666665\n",
      "----------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         8\n",
      "           1       0.89      1.00      0.94         8\n",
      "           2       1.00      1.00      1.00         8\n",
      "           3       1.00      0.88      0.93         8\n",
      "\n",
      "   micro avg       0.97      0.97      0.97        32\n",
      "   macro avg       0.97      0.97      0.97        32\n",
      "weighted avg       0.97      0.97      0.97        32\n",
      " samples avg       0.97      0.97      0.97        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.50      0.67         2\n",
      "           1       1.00      1.00      1.00         2\n",
      "           2       1.00      1.00      1.00         2\n",
      "           3       0.67      1.00      0.80         2\n",
      "\n",
      "   micro avg       0.88      0.88      0.88         8\n",
      "   macro avg       0.92      0.88      0.87         8\n",
      "weighted avg       0.92      0.88      0.87         8\n",
      " samples avg       0.88      0.88      0.88         8\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        16\n",
      "           1       1.00      1.00      1.00        16\n",
      "           2       1.00      1.00      1.00        16\n",
      "           3       1.00      1.00      1.00        16\n",
      "\n",
      "   micro avg       1.00      1.00      1.00        64\n",
      "   macro avg       1.00      1.00      1.00        64\n",
      "weighted avg       1.00      1.00      1.00        64\n",
      " samples avg       1.00      1.00      1.00        64\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.17      0.27        12\n",
      "           1       0.43      0.25      0.32        12\n",
      "           2       0.75      1.00      0.86        12\n",
      "           3       0.36      0.67      0.47        12\n",
      "\n",
      "   micro avg       0.52      0.52      0.52        48\n",
      "   macro avg       0.55      0.52      0.48        48\n",
      "weighted avg       0.55      0.52      0.48        48\n",
      " samples avg       0.52      0.52      0.52        48\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-01-19 11:44:38.855715: I external/local_tsl/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2024-01-19 11:44:39.440893: I external/local_tsl/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 8 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f9bac566de0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 1s 1s/step\n",
      "WARNING:tensorflow:6 out of the last 9 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7f9bac566de0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 0s 385ms/step\n",
      "2/2 [==============================] - 0s 38ms/step\n",
      "1/1 [==============================] - 1s 502ms/step\n",
      "1/1 [==============================] - 0s 63ms/step\n",
      "1/1 [==============================] - 0s 66ms/step\n",
      "1dcnn intra train accuracy = 4.0\n",
      "1dcnn intra test accuracy = 4.0\n",
      "1dcnn cross train accuracy = 4.0\n",
      "1dcnn cross test 1 accuracy = 3.75\n",
      "1dcnn cross test 2 accuracy = 3.125\n",
      "1dcnn cross test 3 accuracy = 3.625\n",
      "1dcnn cross test all accuracy = 3.5\n",
      "----------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         8\n",
      "           1       1.00      1.00      1.00         8\n",
      "           2       1.00      1.00      1.00         8\n",
      "           3       1.00      1.00      1.00         8\n",
      "\n",
      "   micro avg       1.00      1.00      1.00        32\n",
      "   macro avg       1.00      1.00      1.00        32\n",
      "weighted avg       1.00      1.00      1.00        32\n",
      " samples avg       1.00      1.00      1.00        32\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         2\n",
      "           1       1.00      1.00      1.00         2\n",
      "           2       1.00      1.00      1.00         2\n",
      "           3       1.00      1.00      1.00         2\n",
      "\n",
      "   micro avg       1.00      1.00      1.00         8\n",
      "   macro avg       1.00      1.00      1.00         8\n",
      "weighted avg       1.00      1.00      1.00         8\n",
      " samples avg       1.00      1.00      1.00         8\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        16\n",
      "           1       1.00      1.00      1.00        16\n",
      "           2       1.00      1.00      1.00        16\n",
      "           3       1.00      1.00      1.00        16\n",
      "\n",
      "   micro avg       1.00      1.00      1.00        64\n",
      "   macro avg       1.00      1.00      1.00        64\n",
      "weighted avg       1.00      1.00      1.00        64\n",
      " samples avg       1.00      1.00      1.00        64\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.42      0.56        12\n",
      "           1       0.56      0.75      0.64        12\n",
      "           2       0.92      1.00      0.96        12\n",
      "           3       0.77      0.83      0.80        12\n",
      "\n",
      "   micro avg       0.75      0.75      0.75        48\n",
      "   macro avg       0.77      0.75      0.74        48\n",
      "weighted avg       0.77      0.75      0.74        48\n",
      " samples avg       0.75      0.75      0.75        48\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "def test_models(model1_path, model2_path, intra_data, cross_data, model_name):\n",
    "\n",
    "    ### uncomment if you want to use integer labels\n",
    "    y_train_intra = np.argmax(intra_data[0].one_hot_encoded_labels, 1) \n",
    "    y_test_intra = np.argmax(intra_data[1].one_hot_encoded_labels, 1)\n",
    "\n",
    "    y_train_cross = np.argmax(cross_data[0].one_hot_encoded_labels, 1) \n",
    "    y_test_cross1 = np.argmax(cross_data[1].one_hot_encoded_labels, 1) \n",
    "    y_test_cross2 = np.argmax(cross_data[2].one_hot_encoded_labels, 1) \n",
    "    y_test_cross3 = np.argmax(cross_data[3].one_hot_encoded_labels, 1) \n",
    "\n",
    "    ### one hot encoded labels\n",
    "    # y_train_intra = intra_data[0].one_hot_encoded_labels\n",
    "    # y_test_intra = intra_data[1].one_hot_encoded_labels\n",
    "\n",
    "    # y_train_cross = cross_data[0].one_hot_encoded_labels\n",
    "    # y_test_cross1 = cross_data[1].one_hot_encoded_labels\n",
    "    # y_test_cross2 = cross_data[2].one_hot_encoded_labels\n",
    "    # y_test_cross3 = cross_data[3].one_hot_encoded_labels\n",
    "\n",
    "    y_test_cross_all = np.concatenate([y_test_cross1, y_test_cross2, y_test_cross3])\n",
    "\n",
    "    model_intra = tf.keras.models.load_model(model1_path)\n",
    "    y_predicted_train_intra = np.argmax(model_intra.predict(intra_data[0].processed_matrices), 1)\n",
    "    y_predicted_test_intra = np.argmax(model_intra.predict(intra_data[1].processed_matrices), 1)\n",
    "\n",
    "    del model_intra\n",
    "    tf.keras.backend.clear_session()\n",
    "\n",
    "    model_cross = tf.keras.models.load_model(model2_path)\n",
    "    y_predicted_train_cross = np.argmax(model_cross.predict(cross_data[0].processed_matrices), 1)\n",
    "    y_predicted_test_cross1 = np.argmax(model_cross.predict(cross_data[1].processed_matrices), 1)\n",
    "    y_predicted_test_cross2 = np.argmax(model_cross.predict(cross_data[2].processed_matrices), 1)\n",
    "    y_predicted_test_cross3 = np.argmax(model_cross.predict(cross_data[3].processed_matrices), 1)\n",
    "    y_predicted_test_cross_all = np.concatenate([y_predicted_test_cross1, y_predicted_test_cross2, y_predicted_test_cross3])\n",
    "\n",
    "    ### binarize back - use only if you have integer based labels\n",
    "    # y_predicted_train_intra = np.asarray([[int(idx == pred) for idx in range(4)]for pred in y_predicted_train_intra])\n",
    "    # y_predicted_test_intra =np.asarray([[int(idx == pred) for idx in range(4)]for pred in y_predicted_test_intra])\n",
    "\n",
    "    # y_predicted_train_cross = np.asarray([[int(idx == pred) for idx in range(4)]for pred in y_predicted_train_cross])\n",
    "    # y_predicted_test_cross1 = np.asarray([[int(idx == pred) for idx in range(4)]for pred in y_predicted_test_cross1])\n",
    "    # y_predicted_test_cross2 = np.asarray([[int(idx == pred) for idx in range(4)]for pred in y_predicted_test_cross2])\n",
    "    # y_predicted_test_cross3 = np.asarray([[int(idx == pred) for idx in range(4)]for pred in y_predicted_test_cross3])\n",
    "    # y_predicted_test_cross_all = np.asarray([[int(idx == pred) for idx in range(4)]for pred in y_predicted_test_cross_all])\n",
    "\n",
    "    del model_cross\n",
    "    tf.keras.backend.clear_session()\n",
    "\n",
    "    ### metrics\n",
    "\n",
    "    intra_train_acc = np.sum(y_predicted_train_intra == y_train_intra) / len(y_predicted_train_intra)\n",
    "    intra_test_acc = np.sum(y_predicted_test_intra == y_test_intra) / len(y_predicted_test_intra)\n",
    "\n",
    "    cross_train_acc = np.sum(y_predicted_train_cross == y_train_cross) / len(y_predicted_train_cross)\n",
    "    cross_test1_acc = np.sum(y_predicted_test_cross1 == y_test_cross1) / len(y_predicted_test_cross1)\n",
    "    cross_test2_acc = np.sum(y_predicted_test_cross2 == y_test_cross2) / len(y_predicted_test_cross2)\n",
    "    cross_test3_acc = np.sum(y_predicted_test_cross3 == y_test_cross3) / len(y_predicted_test_cross3)\n",
    "    cross_test_all_acc = np.mean([cross_test1_acc, cross_test2_acc, cross_test3_acc])\n",
    "\n",
    "    report_intra_train = classification_report(y_train_intra, y_predicted_train_intra)\n",
    "    report_cross_train = classification_report(y_train_cross, y_predicted_train_cross)\n",
    "\n",
    "    report_intra_test = classification_report(y_test_intra, y_predicted_test_intra)\n",
    "    report_cross_test_all = classification_report(y_test_cross_all, y_predicted_test_cross_all)\n",
    "\n",
    "    print(f\"{model_name} intra train accuracy = {intra_train_acc}\")\n",
    "    print(f\"{model_name} intra test accuracy = {intra_test_acc}\")\n",
    "    print(f\"{model_name} cross train accuracy = {cross_train_acc}\")\n",
    "    print(f\"{model_name} cross test 1 accuracy = {cross_test1_acc}\")\n",
    "    print(f\"{model_name} cross test 2 accuracy = {cross_test2_acc}\")\n",
    "    print(f\"{model_name} cross test 3 accuracy = {cross_test3_acc}\")\n",
    "    print(f\"{model_name} cross test all accuracy = {cross_test_all_acc}\")\n",
    "    print(\"----------------\")\n",
    "    print(report_intra_train)\n",
    "    print(report_intra_test)\n",
    "    print(report_cross_train)\n",
    "    print(report_cross_test_all)\n",
    "\n",
    "    # save predictions to file\n",
    "    pickle.dump(y_predicted_train_intra, open(f\"predictions/{model_name}/y_predicted_train_intra.pickle\", \"wb\"))\n",
    "    pickle.dump(y_predicted_test_intra, open(f\"predictions/{model_name}/y_predicted_test_intra.pickle\", \"wb\"))\n",
    "    pickle.dump(y_predicted_train_cross, open(f\"predictions/{model_name}/y_predicted_train_cross.pickle\", \"wb\"))\n",
    "    pickle.dump(y_predicted_test_cross1, open(f\"predictions/{model_name}/y_predicted_test_cross1.pickle\", \"wb\"))\n",
    "    pickle.dump(y_predicted_test_cross2, open(f\"predictions/{model_name}/y_predicted_test_cross2.pickle\", \"wb\"))\n",
    "    pickle.dump(y_predicted_test_cross3, open(f\"predictions/{model_name}/y_predicted_test_cross3.pickle\", \"wb\"))\n",
    "    pickle.dump(y_predicted_test_cross_all, open(f\"predictions/{model_name}/y_predicted_test_cross_all.pickle\", \"wb\"))\n",
    "    \n",
    "    return y_predicted_train_intra, y_predicted_test_intra, y_predicted_train_cross, y_predicted_test_cross1, y_predicted_test_cross2, y_predicted_test_cross3, y_predicted_test_cross_all\n",
    "\n",
    "y_predicted_train_intra_lstm, y_predicted_test_intra_lstm, y_predicted_train_cross_lstm, y_predicted_test_cross1_lstm, y_predicted_test_cross2_lstm, y_predicted_test_cross3_lstm, y_predicted_test_cross_all_lstm = test_models('models/lstm_intra.keras', 'models/lstm_cross.keras', [train_data_intra, test_data_intra], [train_data_cross, test_data_cross1, test_data_cross2, test_data_cross3], \"lstm\")\n",
    "y_predicted_train_intra_1dcnn, y_predicted_test_intra_1dcnn, y_predicted_train_cross_1dcnn, y_predicted_test_cross1_1dcnn, y_predicted_test_cross2_1dcnn, y_predicted_test_cross3_1dcnn, y_predicted_test_cross_all_1dcnn = test_models('models/1dcnn_intra.keras', 'models/1dcnn_cross.keras', [train_data_intra, test_data_intra], [train_data_cross, test_data_cross1, test_data_cross2, test_data_cross3], \"1dcnn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_mapping_bin_text = {\n",
    "    \"0001\": 'Working memory task',\n",
    "    \"1000\": 'Math and story task',\n",
    "    \"0100\": 'Motor task',\n",
    "    \"0010\": 'Resting task',\n",
    "}\n",
    "\n",
    "def convert_label_to_text(predicted):\n",
    "    return np.asarray([label_mapping_bin_text[\"\".join(pred.astype(str))]for pred in predicted])\n",
    "\n",
    "### save text labels predictions to file\n",
    "y_predicted_train_cross_1dcnn = convert_label_to_text(y_predicted_train_cross_1dcnn)\n",
    "y_predicted_test_cross1_1dcnn = convert_label_to_text(y_predicted_test_cross1_1dcnn)\n",
    "y_predicted_test_cross2_1dcnn = convert_label_to_text(y_predicted_test_cross2_1dcnn)\n",
    "y_predicted_test_cross3_1dcnn = convert_label_to_text(y_predicted_test_cross3_1dcnn)\n",
    "y_predicted_test_cross_all_1dcnn = convert_label_to_text(y_predicted_test_cross_all_1dcnn)\n",
    "\n",
    "y_predicted_test_intra_1dcnn = convert_label_to_text(y_predicted_test_intra_1dcnn)\n",
    "y_predicted_train_intra_1dcnn = convert_label_to_text(y_predicted_train_intra_1dcnn)\n",
    "\n",
    "y_predicted_train_cross_lstm = convert_label_to_text(y_predicted_train_cross_lstm)\n",
    "y_predicted_test_cross1_lstm = convert_label_to_text(y_predicted_test_cross1_lstm)\n",
    "y_predicted_test_cross2_lstm = convert_label_to_text(y_predicted_test_cross2_lstm)\n",
    "y_predicted_test_cross3_lstm = convert_label_to_text(y_predicted_test_cross3_lstm)\n",
    "y_predicted_test_cross_all_lstm = convert_label_to_text(y_predicted_test_cross_all_lstm)\n",
    "\n",
    "y_predicted_test_intra_lstm = convert_label_to_text(y_predicted_test_intra_lstm)\n",
    "y_predicted_train_intra_lstm = convert_label_to_text(y_predicted_train_intra_lstm)\n",
    "\n",
    "# !rm \"1dcnn_pred.txt\"\n",
    "# !rm \"lstm_pred.txt\"\n",
    "\n",
    "real_labels = [train_data_intra.one_hot_encoded_labels, test_data_intra.one_hot_encoded_labels, train_data_cross.one_hot_encoded_labels, test_data_cross1.one_hot_encoded_labels, test_data_cross2.one_hot_encoded_labels, test_data_cross3.one_hot_encoded_labels]\n",
    "names = [\"train_intra\", \"test_intra\", \"train_cross\", \"test_cross1\", \"test_cross2\", \"test_cross3\", \"test_crossall\"]\n",
    "with open(\"lstm_pred.txt\", \"a\") as file:\n",
    "    variables = [y_predicted_train_intra_lstm, y_predicted_test_intra_lstm, y_predicted_train_cross_lstm, y_predicted_test_cross1_lstm, y_predicted_test_cross2_lstm, y_predicted_test_cross3_lstm, y_predicted_test_cross_all_lstm]\n",
    "\n",
    "    for name, variable, real_var in zip(names, variables, real_labels):\n",
    "        file.write(name + \"-----------------\\n\")\n",
    "        file.write(\"PREDICTED\\n\")\n",
    "        file.write(\"\\n\".join(convert_label_to_text(variable)) + \"\\n\")\n",
    "        file.write(\"/////////////\\n\")\n",
    "        file.write(\"REAL\\n\")\n",
    "        file.write(\"\\n\".join(convert_label_to_text(real_var)) + \"\\n\")\n",
    "        file.write(\"=======================\\n\")\n",
    "\n",
    "with open(\"1dcnn_pred.txt\", \"a\") as file:\n",
    "    variables = [y_predicted_train_intra_1dcnn, y_predicted_test_intra_1dcnn, y_predicted_train_cross_1dcnn, y_predicted_test_cross1_1dcnn, y_predicted_test_cross2_1dcnn, y_predicted_test_cross3_1dcnn, y_predicted_test_cross_all_1dcnn]\n",
    "\n",
    "    for name, variable, real_var in zip(names, variables, real_labels):\n",
    "        file.write(name + \"-----------------\\n\")\n",
    "        file.write(\"PREDICTED\\n\")\n",
    "        file.write(\"\\n\".join(convert_label_to_text(variable)) + \"\\n\")\n",
    "        file.write(\"/////////////\\n\")\n",
    "        file.write(\"REAL\\n\")\n",
    "        file.write(\"\\n\".join(convert_label_to_text(real_var)) + \"\\n\")\n",
    "        file.write(\"=======================\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23 13 2 10\n",
      "McNemar's test cross: 6.666666666666667\n",
      "7 1 0 0\n",
      "McNemar's test intra: 0.0\n"
     ]
    }
   ],
   "source": [
    "# integer labels\n",
    "# y_test_cross1 = np.argmax(test_data_cross1.one_hot_encoded_labels, 1) \n",
    "# y_test_cross2 = np.argmax(test_data_cross2.one_hot_encoded_labels, 1) \n",
    "# y_test_cross3 = np.argmax(test_data_cross3.one_hot_encoded_labels, 1) \n",
    "# y_test_cross_all = np.concatenate([y_test_cross1, y_test_cross2, y_test_cross3])\n",
    "# y_test_intra = np.argmax(test_data_intra.one_hot_encoded_labels, 1)\n",
    "\n",
    "# one hot encoded labels\n",
    "y_test_cross1 = test_data_cross1.one_hot_encoded_labels \n",
    "y_test_cross2 = test_data_cross2.one_hot_encoded_labels \n",
    "y_test_cross3 = test_data_cross3.one_hot_encoded_labels \n",
    "y_test_cross_all = np.concatenate([y_test_cross1, y_test_cross2, y_test_cross3])\n",
    "y_test_intra = test_data_intra.one_hot_encoded_labels\n",
    "\n",
    "both_correct = 0\n",
    "both_incorrect = 0\n",
    "lstm_correct = 0\n",
    "cnn_correct = 0\n",
    "\n",
    "# only works for one hot encoded labels\n",
    "# since the data are binarised, bitwise operations are useful to calculate the correct/wrong predictions of both models\n",
    "# +2 is needed because the negation (~) operation flips the sign-bit in front of the numbers\n",
    "for lstm, cnn, real in zip(y_predicted_test_cross_all_lstm, y_predicted_test_cross_all_1dcnn, y_test_cross_all):\n",
    "    both_correct += np.sum(lstm & real) == 1 and np.sum(cnn & real) == 1\n",
    "    both_incorrect += np.sum((~(lstm & real) + 2)) == 4 and np.sum((~(cnn & real) + 2)) == 4\n",
    "    lstm_correct += np.sum(lstm & real) == 1 and np.sum((~(cnn & real) + 2)) == 4\n",
    "    cnn_correct += np.sum((~(lstm & real) + 2)) == 4 and np.sum(cnn & real) == 1\n",
    "\n",
    "# a, b, c, d\n",
    "print(both_correct, cnn_correct, lstm_correct, both_incorrect)\n",
    "mc = ((abs(cnn_correct - lstm_correct) - 1)**2)/(cnn_correct + lstm_correct)\n",
    "print(f\"McNemar's test cross: {mc}\")\n",
    "\n",
    "both_correct = 0\n",
    "both_incorrect = 0\n",
    "lstm_correct = 0\n",
    "cnn_correct = 0\n",
    "\n",
    "# only works for one hot encoded labels\n",
    "for lstm, cnn, real in zip(y_predicted_test_intra_lstm, y_predicted_test_intra_1dcnn, y_test_intra):\n",
    "    both_correct += np.sum(lstm & real) == 1 and np.sum(cnn & real) == 1\n",
    "    both_incorrect += np.sum((~(lstm & real) + 2)) == 4 and np.sum((~(cnn & real) + 2)) == 4\n",
    "    lstm_correct += np.sum(lstm & real) == 1 and np.sum((~(cnn & real) + 2)) == 4\n",
    "    cnn_correct += np.sum((~(lstm & real) + 2)) == 4 and np.sum(cnn & real) == 1\n",
    "\n",
    "# a, b, c, d\n",
    "print(both_correct, cnn_correct, lstm_correct, both_incorrect)\n",
    "mc = ((abs(cnn_correct - lstm_correct) - 1)**2)/(cnn_correct + lstm_correct)\n",
    "print(f\"McNemar's test intra: {mc}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prdl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
